{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader,Dataset\nimport tqdm\nimport os \nimport torch.functional as f\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:52:14.348679Z","iopub.execute_input":"2023-07-12T13:52:14.349117Z","iopub.status.idle":"2023-07-12T13:52:17.490557Z","shell.execute_reply.started":"2023-07-12T13:52:14.349084Z","shell.execute_reply":"2023-07-12T13:52:17.489371Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# monte carlo tree search \n*given a state and possible paths from state the algorithm search in every path and updates the win counts after every path which makes us able to stop the search at a ntermediate level and still get results on learned path*\n","metadata":{}},{"cell_type":"code","source":"class TicTacToe:\n    def __init__(self):\n        self.row_count = 3\n        self.column_count = 3\n        self.action_size = self.row_count * self.column_count\n        \n    def get_initial_state(self):\n        return np.zeros((self.row_count, self.column_count))\n    \n    def get_next_state(self, state, action, player):\n        row = action // self.column_count\n        column = action % self.column_count\n        state[row, column] = player\n        return state\n    \n    def get_valid_moves(self, state):\n        return (state.reshape(-1) == 0).astype(np.uint8)\n    \n    def check_win(self, state, action):\n        if action == None:\n            return False\n        \n        row = action // self.column_count\n        column = action % self.column_count\n        player = state[row, column]\n        \n        return (\n            np.sum(state[row, :]) == player * self.column_count\n            or np.sum(state[:, column]) == player * self.row_count\n            or np.sum(np.diag(state)) == player * self.row_count\n            or np.sum(np.diag(np.flip(state, axis=0))) == player * self.row_count\n        )\n    \n    def get_value_and_terminated(self, state, action):\n        if self.check_win(state, action):\n            return 1, True\n        if np.sum(self.get_valid_moves(state)) == 0:\n            return 0, True\n        return 0, False\n    \n    def get_opponent(self, player):\n        return -player\n    \n    def get_opponent_value(self, value):\n        return -value\n    \n    def change_perspective(self, state, player):\n        return state * player\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-12T13:52:17.492741Z","iopub.execute_input":"2023-07-12T13:52:17.493353Z","iopub.status.idle":"2023-07-12T13:52:17.511899Z","shell.execute_reply.started":"2023-07-12T13:52:17.493321Z","shell.execute_reply":"2023-07-12T13:52:17.510145Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# verify the game","metadata":{}},{"cell_type":"code","source":"game = TicTacToe()\nboard = game.get_initial_state()\nplayer = 1\nwhile True:\n    print(board)\n    valid_moves = game.get_valid_moves(board)\n    print([i for i in range(0,len(valid_moves)) if valid_moves[i]==True])\n    move = int(input())\n    if(valid_moves[move]==False):\n         print('invalid_move')\n         break\n    board = game.get_next_state(board,move,player)\n    print(board)        \n    player = game.get_opponent(player)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# class Node for MCTS","metadata":{}},{"cell_type":"code","source":"class Node:\n    def __init__(self, game, args, state, parent=None, action_taken=None):\n        self.game = game\n        self.args = args\n        self.state = state\n        self.parent = parent\n        self.action_taken = action_taken\n        \n        self.children = []\n        self.expandable_moves = game.get_valid_moves(state)\n        \n        self.visit_count = 0\n        self.value_sum = 0\n        \n    def is_fully_expanded(self):\n        return np.sum(self.expandable_moves) == 0 and len(self.children) > 0\n    \n    def select(self):\n        best_child = None\n        best_ucb = -np.inf\n        \n        for child in self.children:\n            ucb = self.get_ucb(child)\n            if ucb > best_ucb:\n                best_child = child\n                best_ucb = ucb\n                \n        return best_child\n    \n    def get_ucb(self, child):\n        q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n        return q_value + self.args['C'] * math.sqrt(math.log(self.visit_count) / child.visit_count)\n    \n    def expand(self):\n        action = np.random.choice(np.where(self.expandable_moves == 1)[0])\n        self.expandable_moves[action] = 0\n        \n        child_state = self.state.copy()\n        child_state = self.game.get_next_state(child_state, action, 1)\n        child_state = self.game.change_perspective(child_state, player=-1)\n        \n        child = Node(self.game, self.args, child_state, self, action)\n        self.children.append(child)\n        return child\n    \n    def simulate(self):\n        value, is_terminal = self.game.get_value_and_terminated(self.state, self.action_taken)\n        value = self.game.get_opponent_value(value)\n        \n        if is_terminal:\n            return value\n        \n        rollout_state = self.state.copy()\n        rollout_player = 1\n        while True:\n            valid_moves = self.game.get_valid_moves(rollout_state)\n            action = np.random.choice(np.where(valid_moves == 1)[0])\n            rollout_state = self.game.get_next_state(rollout_state, action, rollout_player)\n            value, is_terminal = self.game.get_value_and_terminated(rollout_state, action)\n            if is_terminal:\n                if rollout_player == -1:\n                    value = self.game.get_opponent_value(value)\n                return value    \n            \n            rollout_player = self.game.get_opponent(rollout_player)\n            \n    def backpropagate(self, value):\n        self.value_sum += value\n        self.visit_count += 1\n        \n        value = self.game.get_opponent_value(value)\n        if self.parent is not None:\n            self.parent.backpropagate(value)  \n\n\nclass MCTS:\n    def __init__(self, game, args):\n        self.game = game\n        self.args = args\n        \n    def search(self, state):\n        root = Node(self.game, self.args, state)\n        \n        for search in range(self.args['num_searches']):\n            node = root\n            \n            while node.is_fully_expanded():\n                node = node.select()\n                \n            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n            value = self.game.get_opponent_value(value)\n            \n            if not is_terminal:\n                node = node.expand()\n                value = node.simulate()\n                \n            node.backpropagate(value)    \n            \n            \n        action_probs = np.zeros(self.game.action_size)\n        for child in root.children:\n            action_probs[child.action_taken] = child.visit_count\n        action_probs /= np.sum(action_probs)\n        return action_probs\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:55:54.542327Z","iopub.execute_input":"2023-07-12T13:55:54.542830Z","iopub.status.idle":"2023-07-12T13:55:54.568956Z","shell.execute_reply.started":"2023-07-12T13:55:54.542795Z","shell.execute_reply":"2023-07-12T13:55:54.567549Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Monte carlo tree search**\n1.         #select -> select the leaf node of tree by following highest uct value\n2.         #expand -> add a node to the leaf node\n3.         #simulate -> from the newly added node continue the game \n4.         #backprop -> when game ends backproppagate with the game outcome and visitcount\n5.         #return the value with highest ubc value\n# uct = no.of.wins / no.of visits + sqrt(log(parentvisits)/childvisits)","metadata":{}},{"cell_type":"code","source":"class MCTS:\n    def __init__(self, game, args):\n        self.game = game\n        self.args = args\n        \n    def search(self, state):\n        root = Node(self.game, self.args, state)\n        \n        for search in range(self.args['num_searches']):\n            node = root\n            \n            while node.is_fully_expanded():\n                node = node.select()\n                \n            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n            value = self.game.get_opponent_value(value)\n            \n            if not is_terminal:\n                node = node.expand()\n                value = node.simulate()\n                \n            node.backpropagate(value)    \n            \n            \n        action_probs = np.zeros(self.game.action_size)\n        for child in root.children:\n            action_probs[child.action_taken] = child.visit_count\n        action_probs /= np.sum(action_probs)\n        return action_probs\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:55:59.828182Z","iopub.execute_input":"2023-07-12T13:55:59.828654Z","iopub.status.idle":"2023-07-12T13:55:59.839708Z","shell.execute_reply.started":"2023-07-12T13:55:59.828622Z","shell.execute_reply":"2023-07-12T13:55:59.838330Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tictactoe = TicTacToe()\nplayer = 1\n\nargs = {\n    'C': 1.41,\n    'num_searches': 1000\n}\n\nmcts = MCTS(tictactoe, args)\n\nstate = tictactoe.get_initial_state()\n\n\nwhile True:\n    print(state)\n    \n    if player == 1:\n        valid_moves = tictactoe.get_valid_moves(state)\n        print(\"valid_moves\", [i for i in range(tictactoe.action_size) if valid_moves[i] == 1])\n        action = int(input(f\"{player}:\"))\n\n        if valid_moves[action] == 0:\n            print(\"action not valid\")\n            continue\n            \n    else:\n        neutral_state = tictactoe.change_perspective(state, player)\n        mcts_probs = mcts.search(neutral_state)\n        action = np.argmax(mcts_probs)\n        \n    state = tictactoe.get_next_state(state, action, player)\n    \n    value, is_terminal = tictactoe.get_value_and_terminated(state, action)\n    \n    if is_terminal:\n        print(state)\n        if value == 1:\n            print(player, \"won\")\n        else:\n            print(\"draw\")\n        break\n        \n    player = tictactoe.get_opponent(player)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T13:56:03.118401Z","iopub.execute_input":"2023-07-12T13:56:03.118852Z","iopub.status.idle":"2023-07-12T13:56:45.967061Z","shell.execute_reply.started":"2023-07-12T13:56:03.118819Z","shell.execute_reply":"2023-07-12T13:56:45.966081Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\nvalid_moves [0, 1, 2, 3, 4, 5, 6, 7, 8]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"1: 0\n"},{"name":"stdout","text":"[[1. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n[[ 1.  0.  0.]\n [ 0. -1.  0.]\n [ 0.  0.  0.]]\nvalid_moves [1, 2, 3, 5, 6, 7, 8]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"1: 3\n"},{"name":"stdout","text":"[[ 1.  0.  0.]\n [ 1. -1.  0.]\n [ 0.  0.  0.]]\n[[ 1.  0.  0.]\n [ 1. -1.  0.]\n [-1.  0.  0.]]\nvalid_moves [1, 2, 5, 7, 8]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"1: 2\n"},{"name":"stdout","text":"[[ 1.  0.  1.]\n [ 1. -1.  0.]\n [-1.  0.  0.]]\n[[ 1. -1.  1.]\n [ 1. -1.  0.]\n [-1.  0.  0.]]\nvalid_moves [5, 7, 8]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"1: 7\n"},{"name":"stdout","text":"[[ 1. -1.  1.]\n [ 1. -1.  0.]\n [-1.  1.  0.]]\n[[ 1. -1.  1.]\n [ 1. -1. -1.]\n [-1.  1.  0.]]\nvalid_moves [8]\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"1: 8\n"},{"name":"stdout","text":"[[ 1. -1.  1.]\n [ 1. -1. -1.]\n [-1.  1.  1.]]\ndraw\n","output_type":"stream"}]}]}